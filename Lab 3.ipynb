{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a7c4fe",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio:\n",
    "Describir la serie de tiempo y visualizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7620ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mostrar_graficas(archivos):\n",
    "    for archivo in archivos:\n",
    "        # Leemos los datos\n",
    "        datos = pd.read_csv(archivo + \".csv\", parse_dates=True, index_col=0)\n",
    "        \n",
    "        # Hacemos el dibujo\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        datos.plot(ax=plt.gca())  # gca es como decir \"dame el eje actual para dibujar\"\n",
    "        plt.title(archivo)\n",
    "        plt.ylabel(datos.columns[0])\n",
    "        plt.xlabel(\"Día o Mes\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Aquí van los nombres de los archivos que vamos a graficar\n",
    "nombres_archivos = [\n",
    "    \"daily-total-female-births\",\n",
    "    \"shampoo\",\n",
    "    \"monthly-mean-temp\",\n",
    "    \"monthly-car-sales\"\n",
    "]\n",
    "\n",
    "mostrar_graficas(nombres_archivos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f8eea",
   "metadata": {},
   "source": [
    "# Evaluacion de modelo\n",
    "- MSE \n",
    "- RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a896204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def evaluate_models(y_true, y_pred):\n",
    "    # RMSE\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "\n",
    "\n",
    "def get_y_pred_y_(data, y_pred_column, y_true_column):\n",
    "    data_clean = data.dropna(subset=[y_pred_column, y_true_column])\n",
    "    \n",
    "    y_pred = data_clean[y_pred_column]\n",
    "    y_true = data_clean[y_true_column]\n",
    "    \n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173d009",
   "metadata": {},
   "source": [
    "# Promedios:\n",
    "• Aplicar métodos de promedios y comparar los resultados con el conjunto original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee787eb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def graficar_con_promedio(filename, ventana=3):\n",
    "    datos = pd.read_csv(filename, parse_dates=True, index_col=0)\n",
    "    \n",
    "    # Sacamos el promedio de los últimos datos y lo ponemos un poquito adelante para \"adivinar\" el siguiente dato\n",
    "    datos['Adivinado'] = datos.rolling(ventana).mean().shift(-ventana+1)\n",
    "    \n",
    "    # Hacemos el dibujito\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(datos.index, datos[datos.columns[0]], label='Real')\n",
    "    plt.plot(datos.index, datos['Adivinado'], label='Adivinado', color='red')\n",
    "    \n",
    "    plt.title(filename)\n",
    "    plt.ylabel(datos.columns[0])\n",
    "    plt.xlabel(\"Día o Mes\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return datos\n",
    "\n",
    "# Estos son los datos con los que vamos a trabajar\n",
    "archivos = [\n",
    "    \"daily-total-female-births.csv\",\n",
    "    \"shampoo.csv\",\n",
    "    \"monthly-mean-temp.csv\",\n",
    "    \"monthly-car-sales.csv\"\n",
    "]\n",
    "\n",
    "# Cuántos datos tomamos para el promedio\n",
    "ventana = 3\n",
    "\n",
    "for archivo in archivos:\n",
    "    datos = graficar_con_promedio(archivo, ventana)\n",
    "    y_true, y_pred  = get_y_pred_y_(data=datos, y_pred_column=\"Adivinado\", y_true_column=datos.columns[0])\n",
    "    evaluate_models(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d53e15",
   "metadata": {},
   "source": [
    "# 3. Sarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "def predecir_con_sarima(nombre_archivo, numero_de_predicciones=12):\n",
    "    # Leer el archivo\n",
    "    datos = pd.read_csv(nombre_archivo + \".csv\")\n",
    "    \n",
    "    # Tomar solo la columna de valores\n",
    "    valores = datos[datos.columns[1]].values\n",
    "    \n",
    "    # Crear el modelo y entrenarlo\n",
    "    modelo = SARIMAX(valores, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    modelo_listo = modelo.fit(disp=False)\n",
    "    \n",
    "    # Hacer las predicciones para fechas futuras\n",
    "    predicciones = modelo_listo.predict(len(valores), len(valores) + numero_de_predicciones - 1)\n",
    "    \n",
    "    # Hacer predicciones dentro del rango de tiempo existente (insample)\n",
    "    pred_sarima_insample = modelo_listo.predict(0, len(valores) - 1)\n",
    "    \n",
    "    # Evaluar el rendimiento del modelo con datos existentes\n",
    "    evaluate_models(valores, pred_sarima_insample)\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(valores, label='Datos reales')\n",
    "    plt.plot(range(len(valores), len(valores) + numero_de_predicciones), predicciones, color='red', label='Predicciones')\n",
    "    plt.title(nombre_archivo)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return valores, predicciones\n",
    "\n",
    "# Archivos a analizar\n",
    "archivos = [\n",
    "    \"daily-total-female-births\",\n",
    "    \"shampoo\",\n",
    "    \"monthly-mean-temp\",\n",
    "    \"monthly-car-sales\"\n",
    "]\n",
    "\n",
    "# Para cada archivo, hacer la predicción y mostrarla\n",
    "for archivo in archivos:\n",
    "    y_true, y_pred = predecir_con_sarima(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39db9ff",
   "metadata": {},
   "source": [
    "# 4. Alisamiento exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93832a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "def evaluate_models_2(y_true, y_pred, model_name):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f'{model_name} - RMSE: {rmse}, MAE: {mae}')\n",
    "    \n",
    "def predice_cosas(archivo, pasos=12):\n",
    "    # Abrir archivo\n",
    "    datos = pd.read_csv(archivo + \".csv\")\n",
    "    \n",
    "    # Tomar solo la columna con los números\n",
    "    serie = datos[datos.columns[1]].values\n",
    "    \n",
    "    # Alisado simple\n",
    "    modelo_simple = SimpleExpSmoothing(serie).fit()\n",
    "    pred_simple = modelo_simple.forecast(steps=pasos)\n",
    "    pred_simple_insample = modelo_simple.fittedvalues\n",
    "    evaluate_models_2(serie, pred_simple_insample, \"Alisado simple\")\n",
    "    \n",
    "    # Alisado doble\n",
    "    modelo_doble = ExponentialSmoothing(serie, trend='add').fit()\n",
    "    pred_doble = modelo_doble.forecast(steps=pasos)\n",
    "    pred_doble_insample = modelo_doble.fittedvalues\n",
    "    evaluate_models_2(serie, pred_doble_insample, \"Alisado doble\")\n",
    "    \n",
    "    # SARIMA (modelo complicado)\n",
    "    modelo_sarima = SARIMAX(serie, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    sarima_listo = modelo_sarima.fit(disp=False)\n",
    "    pred_sarima = sarima_listo.predict(len(serie), len(serie) + pasos - 1)\n",
    "    pred_sarima_insample = sarima_listo.predict(0, len(serie) - 1)\n",
    "    evaluate_models_2(serie, pred_sarima_insample, \"SARIMA\")\n",
    "    \n",
    "    # Hacer dibujito\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(serie, label='Datos de verdad')\n",
    "    plt.plot(range(len(serie), len(serie) + pasos), pred_simple, label='Alisado simple', color='blue')\n",
    "    plt.plot(range(len(serie), len(serie) + pasos), pred_doble, label='Alisado doble', color='green')\n",
    "    plt.plot(range(len(serie), len(serie) + pasos), pred_sarima, label='El modelo complicado', color='red')\n",
    "    plt.title(archivo)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Archivos para mirar\n",
    "mis_archivos = [\n",
    "    \"daily-total-female-births\",\n",
    "    \"shampoo\",\n",
    "    \"monthly-mean-temp\",\n",
    "    \"monthly-car-sales\"\n",
    "]\n",
    "\n",
    "# Hacer todo por cada archivo\n",
    "for archivo in mis_archivos:\n",
    "    predice_cosas(archivo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd21f65",
   "metadata": {},
   "source": [
    "# 5. Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba522e82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "\n",
    "def convertir_fecha_custom(fecha):\n",
    "    year, month = fecha.split('-')\n",
    "    year_base = 2021\n",
    "    year_final = year_base + int(year) - 1\n",
    "    return pd.to_datetime(f\"{year_final}-{month}\")\n",
    "\n",
    "def convertir_fecha(fecha, archivo):\n",
    "    if archivo == \"shampoo\":\n",
    "        return convertir_fecha_custom(fecha)\n",
    "    else:\n",
    "        formatos = {\n",
    "            \"daily-total-female-births\": \"%Y-%m-%d\",\n",
    "            \"monthly-mean-temp\": \"%Y-%m\",\n",
    "            \"monthly-car-sales\": \"%Y-%m\"\n",
    "        }\n",
    "        return pd.to_datetime(fecha, format=formatos[archivo], errors='coerce')\n",
    "\n",
    "def predice_con_prophet(archivo, pasos=12):\n",
    "    # Abrir archivo, suponiendo que la primera fila es el encabezado\n",
    "    datos = pd.read_csv(archivo + \".csv\", header=0)\n",
    "    \n",
    "    # Convertir la fecha a formato datetime basado en el archivo\n",
    "    datos['ds'] = datos[datos.columns[0]].apply(lambda x: convertir_fecha(x, archivo))\n",
    "    \n",
    "    # Verificar y eliminar filas con fechas NaN\n",
    "    filas_con_nan = datos[datos['ds'].isna()]\n",
    "    if not filas_con_nan.empty:\n",
    "        print(f\"Eliminando filas con fechas no válidas en {archivo}:\")\n",
    "        print(filas_con_nan)\n",
    "        datos.dropna(subset=['ds'], inplace=True)\n",
    "    \n",
    "    # Preparar datos para Prophet\n",
    "    datos_para_prophet = pd.DataFrame({\n",
    "        'ds': datos['ds'], \n",
    "        'y': datos[datos.columns[1]] # asumimos que la segunda columna contiene los valores\n",
    "    })\n",
    "    \n",
    "    # Crear y entrenar el modelo Prophet\n",
    "    modelo = Prophet(yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False)\n",
    "    modelo.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    modelo.fit(datos_para_prophet)\n",
    "    \n",
    "    # Hacer una predicción con Prophet\n",
    "    futuro = modelo.make_future_dataframe(periods=pasos, freq='M')\n",
    "    predicciones = modelo.predict(futuro)\n",
    "    \n",
    "    # Dibujar todo\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(datos_para_prophet['ds'], datos_para_prophet['y'], label='Datos reales')\n",
    "    plt.plot(predicciones['ds'], predicciones['yhat'], label='Predicciones con Prophet', color='red')\n",
    "    plt.title(archivo)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return datos_para_prophet['y'], predicciones['yhat']\n",
    "\n",
    "# Lista de archivos para mirar\n",
    "mis_archivos = [\n",
    "    \"daily-total-female-births\",\n",
    "    \"shampoo\",\n",
    "    \"monthly-mean-temp\",\n",
    "    \"monthly-car-sales\"\n",
    "]\n",
    "\n",
    "# Hacer todo por cada archivo\n",
    "for archivo in mis_archivos:\n",
    "    y_real, y_pred = predice_con_prophet(archivo)\n",
    "    y_pred_trunc = y_pred[:len(y_real)]\n",
    "\n",
    "    evaluate_models(y_real, y_pred_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def neural_network_forecast(filename, steps=12):\n",
    "    # Leer los datos\n",
    "    data = pd.read_csv(filename + \".csv\")\n",
    "    values = data[data.columns[1]].values\n",
    "    \n",
    "    # Escalar los datos entre 0 y 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    values = scaler.fit_transform(values.reshape(-1, 1))\n",
    "\n",
    "    # Preparar los datos\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - steps):\n",
    "        X.append(values[i:i+steps, 0])\n",
    "        y.append(values[i+steps, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_dim=steps))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Revertir la escala\n",
    "    y = scaler.inverse_transform(y.reshape(-1, 1))\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y, label='Real')\n",
    "    plt.plot(predictions, label='Predicho por NN', color='red')\n",
    "    plt.legend()\n",
    "    plt.title(filename)\n",
    "    plt.show()\n",
    "    return y, predictions\n",
    "\n",
    "\n",
    "# Lista de archivos para mirar\n",
    "mis_archivos = [\n",
    "    \"daily-total-female-births\",\n",
    "    \"shampoo\",\n",
    "    \"monthly-mean-temp\",\n",
    "    \"monthly-car-sales\"\n",
    "]\n",
    "\n",
    "# Hacer todo por cada archivo\n",
    "for archivo in mis_archivos:\n",
    "    y_true, y_pred = neural_network_forecast(archivo)\n",
    "    evaluate_models(y_true, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
